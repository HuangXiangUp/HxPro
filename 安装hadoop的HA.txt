配置jdk
vi /etc/profile
export JAVA_HOME=/usr/java/jdk-版本号
exprot CLASSPATH=${JAVA_HOME}/lib
export PATH=$PATH:${JAVA_HOME}
因为修改了/etc/profile所以用命令使之生效
source /etc/profile
输入命令java -version出现版本号即为生效


配置ssh免密登录
先生成密钥
ssh-keygen -t
将公钥复制到其他机子
ssh-copy-id -i .ssh/id_rsa.pub root@izwz9b1oyj51vpxsgxo5wsz


配置集群hosts
sudo vi /etc/hosts

配置hadoop-env.sh
export JAVA_HOME=/home/hadoop/jdk-12.0.2


配置~/.bash_profile
HADOOP_HOME=/home/hadoop/hadoop-2.7.7
export HADOOP_HOME
PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH
export PATH

配置core-site.xml------------------------------------------------
        <!--配置HDFS主节点的地址，也就是namenode-->
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hx01</value>
        </property>
        <!--配置hdfs数据块和元信息保存再操作系统得目录位置-->
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/root/mapr/hadoop-2.7.7/tmp</value>
        </property>
        <!--指定zookeeper的地址-->
        <property>
                <name>ha.zookeeper.quorum</name>
                <value>hadoop01:2181,hadoop02:2181,hadoop03:2181</value>
        </property>
	
--------------------------------------------------------------------------------
配置hdfs-site.xml-----------------------------------------

        <!--配置HDFS的nameservices为ns1，需要和core-site.xml一致，也就是namenode-->
        <property>
                <name>dfs.nameservices</name>
                <value>hx01</value>
        </property>
        <!--nameservices下面有两个namenode，分别为hx02，hx03-->	
        <property>
                <name>dfs.ha.namenodes.hx01</name>
                <value>hx02,hx03</value>
        </property>
        <!--hx02的rpc通信地址-->	
        <property>
                <name>dfs.namenode.rpc-address.hx01.hx02</name>
                <value>hadoop02:9000</value>
        </property>
        <!--hx02的http通信地址-->	
        <property>
                <name>dfs.namenode.http-address.hx01.hx02</name>
                <value>hadoop02:50070</value>
        </property>
        <!--hx03的rpc通信地址-->	
        <property>
                <name>dfs.namenode.rpc-address.hx01.hx03</name>
                <value>hadoop03:9000</value>
        </property>

        <!--hx03的http通信地址-->	
        <property>
                <name>dfs.namenode.http-address.hx01.hx03</name>
                <value>hadoop03:50070</value>
        </property>
        <!--指定namenode的日志在journalnode上的存放位置-->	
        <property>
                <name>dfs.namenode.shared.edits.dir</name>
                <value>qjournal://hadoop02:8485;hadoop03:8485;/hx01</value>
        </property>

        <!--指定journalnode在本地磁盘存放位置-->	
        <property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/home/hadoop/hadoop-2.7.7/journal</value>
        </property>

        <!--开启namedode失败自动切换-->	
        <property>
                <name>dfs.ha.automatic-failover.enabled</name>
                <value>true</value>
        </property>



        <!--开启namedode失败自动切换实现方式-->	
        <property>
                <name>dfs.client.failover.proxy.provider.hx01</name>
                <value>org.apache.hadoop.hdfs.service.namenode.ha.ConfiguredFailoverProxyProvider</value>
        </property>
	
        <!--配置隔离机制方法，多个机制换行分割，即每个机制暂用一行-->	
        <property>
                <name>dfs.ha.fencing.methods</name>
                <value>sshfence
			shell(/bin/true)</value>
        </property>
        <!--ssh免密登录-->	
        <property>
                <name>dfs.ha.fencing.ssh.private-key-files</name>
                <value>/home/hadoop/.ssh/id_rsa</value>
        </property>
        <!--隔离机制超时时间-->	
        <property>
                <name>dfs.ha.fencing.ssh.connect-timeout</name>
                <value>30000</value>
        </property>
mapred-site.xml----------------------------------------------------
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
--------------------------------------------------------------------
yarn-site.xml----------------------
<!--开启高可用性-->	
<property>
	<name>yarn.resourcemanager.ha.enabled</name>
	<value>true</value>
</property>
<!--指定rm的cluster-id-->	
<property>
	<name>yarn.resourcemanager.cluster-id</name>
	<value>yrc</value>
</property>
<!--指定rm名字-->	
<property>
	<name>yarn.resourcemanager.ha.rm-ids</name>
	<value>rm1,rm2</value>
</property>

<!--指定rm地址-->	
<property>
	<name>yarn.resourcemanager.hostname.rm1</name>
	<value>hadoop01</value>
</property>

<property>
	<name>yarn.resourcemanager.hostname.rm2</name>
	<value>hadoop02</value>
</property>
<!--指定zk集群地址-->	
<property>
	<name>yarn.resourcemanager.zk-address</name>
	<value>hadoop01:2181,hadoop02:2181,hadoop03:2181</value>
</property>
<property>
	<name>yarn-nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>

启动zk
先搭建zk集群
vi ~/.bash_profile
ZOOKEEPER_HOME=/home/hadoop/zookeeper-3.4.14
export ZOOKEEPER
PATH=$ZOOKEEPER_HOME/bin:$PATH

source ~/.profile
把cp zoo_sample.cfg zoo.cfg
在里面
设置dataDir=/home/hadoop/zookeeper-3.4.14/tmp
添加
server.1=hadoop01:2888:3888
server.2=hadoop02:2888:3888
server.3=hadoop03:2888:3888
在tmp目录下新建myid文件，里面写1
将配置好的zk复制到其他机器上
去修改其他机器的myid文件
在每台机器启动zk
zkServer.sh start

zkServer.sh status是查寻哪个是leader
后来发现执行zkServer.sh status报错，看了配置，关闭防火墙等，没用，把hadoop01机器上的sever.1=hadoop01:2888:3888改为server.1=0.0.0.0:2888:3888，同理其他机子也改自己的机器名为本地
启动journal
hadoop-daemon.sh start journalnode
格式化
hdfs namenode -format
 将tmp目录拷贝到其他机器的/home/hadoop/hadoop-2.7.3/tmp下
	scp -r dfs/ hadoop@hadoop02:/home/hadoop/hadoop-2.7.7/tmp
在hadoop01执行----------
格式化zookeeper
   hdfs zkfc -formatZK


    start-all.sh
----------------------------

hadoop02上的ResourceManager需要单独启动
	命令：yarn-daemon.sh start resourcemanager

----------------end-----------------------

hdfs namenode -fromat